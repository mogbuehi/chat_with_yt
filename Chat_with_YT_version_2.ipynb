{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mogbuehi/chat_with_yt/blob/main/Chat_with_YT_version_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat with YT\n",
        "\n",
        "A Notebook App powered by GPT-3.5 Turbo LLM and Whisper Text-to-Speech models. Allows you to transcribe a short (less than 10 min) Youtbue video and ask an AI chatbot questions based on that transcript."
      ],
      "metadata": {
        "id": "CBp_NG5RyYfX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvlr46Bh0gmw"
      },
      "source": [
        "# 1. Mount drive and find current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cajr9Vh80DlX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # mounting a drive is different than changing directory, this command is only giving the notebook access to your Google Drive Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pvoo3bDr2uIL"
      },
      "outputs": [],
      "source": [
        "# chaning directory now that drive is mounted\n",
        "%cd '/content/drive/MyDrive/Lonely Octopus/Lunch and Learn'\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtysN2FQSmUK"
      },
      "source": [
        "# 2. Install Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9rpfSUBSrzZ"
      },
      "source": [
        "Install and import Libraries:\n",
        "\n",
        "\n",
        "*   Pytube - Download Youtube videos\n",
        "*   Moviepy - convert video to audio\n",
        "*   Wave - to interact with `.wav` audio files\n",
        "*   OpenAI - Access `Whisper` and `ChatCompletion` models for transcribing audio.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8p_Cfq58RaM8"
      },
      "outputs": [],
      "source": [
        "!pip install pytube moviepy openai wave tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCEfzfSxWu2u"
      },
      "outputs": [],
      "source": [
        "# Importing the necessary modules\n",
        "from pytube import YouTube\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip\n",
        "import wave\n",
        "import openai\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAeZE9o2S6ea"
      },
      "source": [
        "# 3. Define Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up formatting for the notebook"
      ],
      "metadata": {
        "id": "7vDHsqxBQwpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display markdown format\n",
        "from IPython.display import display, Markdown\n",
        "from datetime import datetime\n",
        "def print_md(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "# Example usage:\n",
        "print_md(\"**Bold text**\")\n",
        "print_md(\"_Italic text_\")\n",
        "\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(current_time)"
      ],
      "metadata": {
        "id": "QEdcsatmQvXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnwNIAZaWRWx"
      },
      "source": [
        "## Download the audio from a YouTube Video\n",
        "\n",
        "Using PyTube to download the video from YT video and save the audio to a '.wav' file in `downloads` folder. Returns the `audio_path` and `status_message` string objects\n",
        "\n",
        "Mount Drive and files will be saved to `content/MyDrive/...`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVtXXA48S6Cg"
      },
      "outputs": [],
      "source": [
        "def download_audio(url):\n",
        "    # Load YouTube url into `YouTube` attribute\n",
        "    yt = YouTube(url)\n",
        "    video = yt.streams.filter(only_audio=True, file_extension='mp4').first()\n",
        "\n",
        "    # Create `downloads/` folder if it doesn't exist\n",
        "    folder ='downloads/'\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "\n",
        "    # Downloads only the audio from a YT video and saves it as an `.mp4`\n",
        "    video.download(output_path=folder)\n",
        "    video_path = os.path.join(folder, video.default_filename)\n",
        "\n",
        "    # Convert the audio to .wav format using moviepy\n",
        "    audio = AudioFileClip(video_path)\n",
        "    audio_path = os.path.splitext(video_path)[0] + \".wav\"\n",
        "    audio.write_audiofile(audio_path, codec='pcm_s16le') # wav format codec\n",
        "\n",
        "    # Delete the original mp4 file\n",
        "    os.remove(video_path)\n",
        "\n",
        "    # Status message for users\n",
        "    status_message = 'Audio downloaded successfully'\n",
        "\n",
        "    return audio_path, status_message\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "malBCXQYpzxM"
      },
      "source": [
        "## Break audio file into clips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35h7r7Smpw28"
      },
      "outputs": [],
      "source": [
        "def split_audio(audio_path, clip_size=30, overlap=3):\n",
        "  clip_list =[]\n",
        "  clip_name = os.path.basename(audio_path)[:-4]\n",
        "  folder = 'downloads/clips/'\n",
        "  if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "\n",
        "  with wave.open(audio_path, 'rb') as wf:\n",
        "    # used for dividing clip into pieces\n",
        "    num_frames = wf.getnframes()\n",
        "    framerate = wf.getframerate()\n",
        "    # important for constructing the clips\n",
        "    num_channels = wf.getnchannels()\n",
        "    sample_width = wf.getsampwidth()\n",
        "\n",
        "    audio_size = num_frames / framerate #value in seconds\n",
        "    frame_interval = int(clip_size * framerate - overlap * framerate) # make an int to avoid fractional frames\n",
        "\n",
        "    clip_number = 1\n",
        "    for start in range(0, num_frames, frame_interval):\n",
        "      end = start + clip_size * framerate\n",
        "      # constructing clip\n",
        "      wf.setpos(start)\n",
        "      clip_num_frames = wf.readframes(clip_size * framerate)\n",
        "      clip_path = f'{folder}/{clip_name}_{clip_number}.wav'\n",
        "\n",
        "      # writing clip with same number of channels, width, and framerate\n",
        "      with wave.open(clip_path, 'wb') as wf_clip:\n",
        "        wf_clip.setnchannels(num_channels)\n",
        "        wf_clip.setsampwidth(sample_width)\n",
        "        wf_clip.setframerate(framerate)\n",
        "        wf_clip.writeframes(clip_num_frames)\n",
        "\n",
        "      clip_list.append(clip_path)\n",
        "      clip_number += 1\n",
        "\n",
        "  return clip_list\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyRYMEuCdKkE"
      },
      "source": [
        "## Transcribe Audio Clips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rs7ac7NDd0ow"
      },
      "outputs": [],
      "source": [
        "def transcribe(audio_path):\n",
        "  clip_list = split_audio(audio_path) # helper function\n",
        "  file_name = os.path.basename(audio_path)[:-4]\n",
        "  folder = 'transcripts/'\n",
        "  os.makedirs(folder, exist_ok=True)\n",
        "  transcribed_clips = []\n",
        "\n",
        "  for clip in clip_list:\n",
        "    clip_size = AudioFileClip(audio_path).duration\n",
        "    if clip_size < 0.1:\n",
        "      print(f'Skipping the following clip (less than 0.1 seconds): {clip}')\n",
        "\n",
        "    with open(clip, 'rb') as file: #audio model\n",
        "      transcript = openai.Audio.transcribe(\n",
        "          file=file,\n",
        "          model='whisper-1',\n",
        "          response_format='text',\n",
        "          temperature=0\n",
        "      )\n",
        "\n",
        "    transcribed_clips.append(transcript + '\\n')\n",
        "    full_transcript = ''.join(transcribed_clips)\n",
        "    full_transcript_path = f'transcripts/{file_name}.txt'\n",
        "\n",
        "    with open(full_transcript_path, 'w') as f:\n",
        "      f.write(full_transcript)\n",
        "\n",
        "  return full_transcript, full_transcript_path\n",
        "\n",
        "# # # Test functions, check folder location (Be sure to mount drive)\n",
        "# url = input('Insert YouTube URL here--> ')\n",
        "# audio_path, message = download_audio(url)\n",
        "\n",
        "# with open('openai.txt', 'r') as file:\n",
        "#     api_key = file.readline().strip()  # Read the key and remove any trailing spaces or newlines\n",
        "\n",
        "# openai.api_key = api_key\n",
        "\n",
        "# transcript, transcript_path = transcribe(audio_path)\n",
        "# print_md(transcript)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTkMFy-npxOD"
      },
      "source": [
        "## Compress transcript so that it fits in the context window (less than 4000 tokens ~ 8000 words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Bw69XKPpwms"
      },
      "outputs": [],
      "source": [
        "with open('openai.txt', 'r') as file:\n",
        "    api_key = file.readline().strip()  # Read the key and remove any trailing spaces or newlines\n",
        "\n",
        "openai.api_key = api_key\n",
        "\n",
        "# txt_path = 'transcripts/How to think of GPT as a developer.txt'\n",
        "# with open(txt_path, 'r') as f:\n",
        "#   transcript = f.read()\n",
        "\n",
        "def compress_transcript(transcript='', context=''):\n",
        "  response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo-0613\",\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"You are a text compression robot that is an expert in regex, .\n",
        "        All you do is output a compressed piece of text that retains the semantic meaning of the text.\n",
        "      Only output the compressed text. Also be sure to infer amount of speakers in the text and give that info.\n",
        "      Follow these rules below to generate a compressed transcript and DO NOT under any circumstances show your work.\n",
        "      Again only output the final compressed text.\n",
        "\n",
        "      *Extractive Summarization:* Select the most informative sentences or fragments based on scoring methods (e.g., TF-IDF, sentence embedding similarities).\n",
        "      *Keyword Extraction:* Identify the most relevant terms and ensure they are included in the compressed text to maintain its topical focus.\n",
        "      *Sentence Simplification:* Rewrite sentences to be more concise, removing subordinate clauses and passive constructions where they are not necessary for understanding.\n",
        "      *Pruning Redundant Information:* Remove any repetitions or paraphrased information that does not add new facts or insight.\n",
        "      *Named Entity Recognition (NER):* Highlight and retain named entities such as people, organizations, and locations to ensure that the compressed text maintains its reference points.\n",
        "      *Coreference Resolution:* Ensure that pronouns and referring expressions are resolved to explicit entities, to prevent loss of meaning through the removal of preceding context.\n",
        "      *Discourse Structure Analysis:* Evaluate the logical structure of the text to prioritize sentences that convey the main narrative or argument.\"\"\"\n",
        "      },\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"Summarize the following transcript. {context} Remember, ONLY output the final compressed transcript. Transcript{transcript} \"\n",
        "      }\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=500,\n",
        "  )\n",
        "\n",
        "  compressed_transcript = response['choices'][0]['message']['content']\n",
        "  return compressed_transcript\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " # # Test function\n",
        "  # text = compress_transcript()\n",
        "  # print(text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J88b2GDdPpw"
      },
      "source": [
        "## Chatbot to ask questions about the transcript\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Memory Management\n",
        "\n",
        "How to count tokens: [Github link](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)\n",
        "\n",
        "Slightly out of date. Run the following for up-to-date encodings\n",
        "```\n",
        "from tiktoken.registry import ENCODING_CONSTRUCTORS\n",
        "\n",
        "# List the encodings from the constructors directly\n",
        "available_encodings = list(ENCODING_CONSTRUCTORS.keys())\n",
        "print(\"Available encodings:\", available_encodings)\n",
        "```\n",
        "\n",
        "Helper functions allow us to summarize just the user and AI messages while keeping the system message intact.\n"
      ],
      "metadata": {
        "id": "zcFDBQCt-cIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if messages gets to big, then summarize previous message prior to appending\n",
        "# !pip install tiktoken\n",
        "import tiktoken\n",
        "\n",
        "# Assuming 'tiktoken_ext.openai_public' is both the plugin module and the encoding name\n",
        "encoding_name = \"cl100k_base\"\n",
        "encoding = tiktoken.get_encoding(encoding_name)\n",
        "\n",
        "def num_tokens(string: str, encoding_name: str) -> int:\n",
        "    encoding = tiktoken.get_encoding(encoding_name)\n",
        "    return len(encoding.encode(string))\n",
        "\n",
        "# Troubleshooting-----------------------------------------------\n",
        "# import tiktoken\n",
        "# from tiktoken.registry import _available_plugin_modules\n",
        "# # List available plugin modules\n",
        "# available_plugin_modules = _available_plugin_modules()\n",
        "# print(\"Available plugin modules:\", available_plugin_modules\n",
        "# print(\"Available encodings:\", available_encodings)\n",
        "\n",
        "#--------------------------------------------------------------\n",
        "def user_assistant_content(messages):\n",
        "    keys = ['role', 'content']\n",
        "    extracted = []\n",
        "    for message in messages:\n",
        "        # Check if the role is 'user' or 'assistant'\n",
        "        if message.get('role') in ['user', 'assistant']:\n",
        "            # Extract only the 'role' and 'content' keys\n",
        "            extracted_item = {key: message[key] for key in keys if key in message}\n",
        "            extracted.append(extracted_item)\n",
        "    # Join the contents of the extracted messages with a newline, ensuring 'content' exists\n",
        "    user_assistant = '\\n'.join(msg['content'] for msg in extracted if 'content' in msg)\n",
        "    # print(type(user_assistant))\n",
        "    return user_assistant\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------\n",
        "def all_content(messages):\n",
        "  # Initialize an empty list to hold the content of each message\n",
        "  contents = []\n",
        "  # Loop through each message in the messages list\n",
        "  for message in messages:\n",
        "      # Extract the 'content' key and append it to the contents list\n",
        "      contents.append(message.get('content', ''))  # Default to an empty string if 'content' key is not found\n",
        "  # Join all the contents with a newline character to separate them\n",
        "  all_contents_text = '\\n'.join(contents)\n",
        "  return all_contents_text\n",
        "#--------------------------------------------------------------\n",
        "def manage_memory(messages):\n",
        "    # Get the complete chat content\n",
        "    raw_chat_all = all_content(messages=messages)\n",
        "    # print(f'TYPE:{type(raw_chat_all)}')\n",
        "    # Get the user and assistant chat content\n",
        "    raw_chat_ua = user_assistant_content(messages=messages)\n",
        "\n",
        "    # Check the token count of the entire chat\n",
        "    encoding_name = \"cl100k_base\"\n",
        "    if num_tokens(string=raw_chat_all, encoding_name=encoding_name) > 1500:\n",
        "        # Summarize the user assistant messages using compress() function\n",
        "        summarized_content = compress_transcript(raw_chat_ua, context='Keep response to less than 200 words and extract key phrases')\n",
        "\n",
        "        # Search for first system message and keep it\n",
        "        first_system_message = next((msg for msg in messages if msg.get('role') == 'system'), None)\n",
        "\n",
        "        # Clear the messages list and append the first system message back if it exists\n",
        "        messages.clear()\n",
        "        if first_system_message:\n",
        "          # Add the summarized content as a new system message\n",
        "          messages.append({'role': 'system', 'content': first_system_message + f'''\\nThis is the chat history:{summarized_content}'''})\n",
        "    else:\n",
        "      # Return the potentially modified list of messages\n",
        "      return messages\n",
        "#--------------------------------------------------------------\n",
        "# if user prompt makes system message too long, ask user to make a shorter prompt"
      ],
      "metadata": {
        "id": "TaFQHWiX-gc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chatbot\n",
        "\n",
        "This function will run until user types `exit`. Memory is managed by `manage_memory()` function"
      ],
      "metadata": {
        "id": "BMoPF1Ms-gtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normal chat bot with memory management\n",
        "\n",
        "\n",
        "# Define the manage_memory function (as previously discussed)\n",
        "\n",
        "def chatbot(system_content):\n",
        "    messages = [{\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_content\n",
        "    }]\n",
        "\n",
        "    while True:\n",
        "        # Get user input\n",
        "        user_input = input(\n",
        "            \"\"\"Input your question query type 'exit' to stop-->: \"\"\")\n",
        "\n",
        "        # Break the loop if the user types 'exit'\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        # Prepare the message for the API call\n",
        "        api_messages = messages + [{\"role\": \"user\", \"content\": user_input}]\n",
        "\n",
        "        # Make the API call to OpenAI\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=api_messages,\n",
        "            temperature=0.1,\n",
        "            max_tokens=500,\n",
        "        )\n",
        "\n",
        "        # Extract the AI's response\n",
        "        ai_output = response['choices'][0]['message']['content']\n",
        "        token_count = response['usage']['total_tokens']\n",
        "        # print(f\"AI: {ai_output}\")\n",
        "\n",
        "        # Add the user input and AI response to the messages\n",
        "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": ai_output})\n",
        "\n",
        "        # Timestamp\n",
        "        current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        # Manage memory if needed\n",
        "        messages = manage_memory(messages)\n",
        "\n",
        "        #Display Chatlog\n",
        "        print_md(f'**Chatlog** {current_time}')\n",
        "        print_md(f'\\n---')\n",
        "        print_md(f'**User:** {user_input}')\n",
        "        print_md(f'**AI** {ai_output}')\n",
        "        print_md(f'**token count:** {token_count}')\n",
        "        # At this point, the loop will continue, and the user can enter another message\n",
        "\n",
        "# Example system content\n",
        "# transcript=''\n",
        "# system_content = f\"\"\"You are a nice chatbot having a conversation with a human. Help them answer questions in regards to\n",
        "# the following transcribed audio from a video. Analyze the text and take on the role of an expert in the relavent field.\n",
        "# Here is the transcript {transcript}.\n",
        "\n",
        "# Take your time and think this out\"\"\"\n",
        "\n",
        "# # Call the function to start the chat\n",
        "# chatbot(system_content)\n"
      ],
      "metadata": {
        "id": "BwG6hxN3-0Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Demo in Notebook"
      ],
      "metadata": {
        "id": "3t7WbRFKMUG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell runs an instance of the application\n",
        "\n",
        "# Select Youtube URL------------------------------------------------------------\n",
        "url = input('Insert YouTube URL here--> ')\n",
        "\n",
        "# Downloading audio from the video----------------------------------------------\n",
        "audio_path, message = download_audio(url)\n",
        "\n",
        "# Transcribing the audio--------------------------------------------------------\n",
        "with open('openai.txt', 'r') as file:\n",
        "    api_key = file.readline().strip()\n",
        "\n",
        "openai.api_key = api_key # Loading API key\n",
        "\n",
        "transcript, transcript_path = transcribe(audio_path)\n",
        "print_md(f'**Transcript**: {transcript}')\n",
        "\n",
        "##  Compressing the transcript---------------------------------------------------\n",
        "with open(transcript_path, 'r') as f:\n",
        "  transcript = f.read()\n",
        "\n",
        "transcript = compress_transcript(transcript=transcript) # comment out for language lesson\n",
        "print_md(f'**Compressed:** {transcript}') # comment out for language lesson\n",
        "\n",
        "# Starting the chatbot----------------------------------------------------------\n",
        "system_content = f\"\"\"You are a nice chatbot having a conversation with a human.\n",
        "Help them answer questions in regards tothe following transcribed audio from\n",
        "a video.\n",
        "Analyze the text and take on the role of an expert in the relavent field.\n",
        "Here is the transcript {transcript}.\n",
        "\n",
        "Take your time and think this out\"\"\"\n",
        "\n",
        "# Call the function to start the chat-------------------------------------------\n",
        "chatbot(system_content)"
      ],
      "metadata": {
        "id": "GpK_Ghn_MeLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "List of youtube links to try:\n",
        "\n",
        "---\n",
        "\n",
        "Gurren Lagann (2 mins): https://www.youtube.com/watch?v=s65n0PmvIm4\n",
        "\n",
        "Max Tegmark x Lex Friedman (4 mins): https://www.youtube.com/watch?v=53zaaRp5cfo\n",
        "\n",
        "Video should be less than 10 mins to avoid error"
      ],
      "metadata": {
        "id": "_mIBgQO4URLs"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vvlr46Bh0gmw",
        "vtysN2FQSmUK",
        "eAeZE9o2S6ea",
        "7vDHsqxBQwpx",
        "qnwNIAZaWRWx",
        "malBCXQYpzxM",
        "zyRYMEuCdKkE",
        "KTkMFy-npxOD",
        "-J88b2GDdPpw",
        "BMoPF1Ms-gtq",
        "3t7WbRFKMUG_"
      ],
      "mount_file_id": "1BkpYjopxJ-GuQ8vS4d5aOb99IEFZ-rC2",
      "authorship_tag": "ABX9TyMJvGyK+Vq5Xntf4ESomD1f",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}